diff -NaurbB --exclude=.svn ../ffmpeg/configure ./configure
--- ../ffmpeg/configure	2006-06-30 10:58:24.000000000 +0700
+++ ./configure	2006-06-30 11:15:38.000000000 +0700
@@ -1191,7 +1191,7 @@
     check_func memalign || _memalign="no"
 fi
 
-if test "$_memalign" = "no" -a "$mmx" = "yes" -a "$memalignhack" != "yes"; then
+if test "$_memalign" = "no" -a "$mmx" = "yes" -a "$memalignhack" != "yes" -a $targetos != Darwin; then
     die "Error, no memalign() but SSE enabled, disable it or use --enable-memalign-hack."
 fi
 
diff -NaurbB --exclude=.svn ../ffmpeg/libavcodec/i386/dsputil_mmx.c ./libavcodec/i386/dsputil_mmx.c
--- ../ffmpeg/libavcodec/i386/dsputil_mmx.c	2006-06-30 10:41:13.000000000 +0700
+++ ./libavcodec/i386/dsputil_mmx.c	2006-06-30 09:47:11.000000000 +0700
@@ -52,7 +52,7 @@
 static const uint64_t ff_pb_3F attribute_used __attribute__ ((aligned(8))) = 0x3F3F3F3F3F3F3F3FULL;
 static const uint64_t ff_pb_FC attribute_used __attribute__ ((aligned(8))) = 0xFCFCFCFCFCFCFCFCULL;
 
-#define JUMPALIGN() __asm __volatile (".balign 8"::)
+#define JUMPALIGN() __asm __volatile (BALIGN_8::)
 #define MOVQ_ZERO(regd)  __asm __volatile ("pxor %%" #regd ", %%" #regd ::)
 
 #define MOVQ_WONE(regd) \
@@ -195,7 +195,7 @@
     asm volatile(
         "mov $-128, %%"REG_a"           \n\t"
         "pxor %%mm7, %%mm7              \n\t"
-        ".balign 16                     \n\t"
+        BALIGN_16
         "1:                             \n\t"
         "movq (%0), %%mm0               \n\t"
         "movq (%0, %2), %%mm2           \n\t"
@@ -223,7 +223,7 @@
     asm volatile(
         "pxor %%mm7, %%mm7              \n\t"
         "mov $-128, %%"REG_a"           \n\t"
-        ".balign 16                     \n\t"
+        BALIGN_16
         "1:                             \n\t"
         "movq (%0), %%mm0               \n\t"
         "movq (%1), %%mm2               \n\t"
@@ -366,7 +366,7 @@
 {
     __asm __volatile(
          "lea (%3, %3), %%"REG_a"       \n\t"
-         ".balign 8                     \n\t"
+         BALIGN_8
          "1:                            \n\t"
          "movd (%1), %%mm0              \n\t"
          "movd (%1, %3), %%mm1          \n\t"
@@ -392,7 +392,7 @@
 {
     __asm __volatile(
          "lea (%3, %3), %%"REG_a"       \n\t"
-         ".balign 8                     \n\t"
+         BALIGN_8
          "1:                            \n\t"
          "movq (%1), %%mm0              \n\t"
          "movq (%1, %3), %%mm1          \n\t"
@@ -418,7 +418,7 @@
 {
     __asm __volatile(
          "lea (%3, %3), %%"REG_a"       \n\t"
-         ".balign 8                     \n\t"
+         BALIGN_8
          "1:                            \n\t"
          "movq (%1), %%mm0              \n\t"
          "movq 8(%1), %%mm4             \n\t"
@@ -3101,7 +3101,12 @@
         }
 
 #ifdef CONFIG_SNOW_ENCODER
-        if(mm_flags & MM_SSE2){
+#if defined(__APPLE__)
+        if (0)  // alignment issues with SSE2 code with Apple GCC
+#else
+        if(mm_flags & MM_SSE2)
+#endif
+        {
             c->horizontal_compose97i = ff_snow_horizontal_compose97i_sse2;
             c->vertical_compose97i = ff_snow_vertical_compose97i_sse2;
             c->inner_add_yblock = ff_snow_inner_add_yblock_sse2;
diff -NaurbB --exclude=.svn ../ffmpeg/libavcodec/i386/dsputil_mmx_avg.h ./libavcodec/i386/dsputil_mmx_avg.h
--- ../ffmpeg/libavcodec/i386/dsputil_mmx_avg.h	2006-06-30 10:41:13.000000000 +0700
+++ ./libavcodec/i386/dsputil_mmx_avg.h	2006-06-30 09:54:24.000000000 +0700
@@ -754,7 +754,7 @@
         "lea (%3, %3), %%"REG_a"        \n\t"
         "movq (%1), %%mm0               \n\t"
         PAVGB" 1(%1), %%mm0             \n\t"
-        ".balign 8                      \n\t"
+        BALIGN_8
         "1:                             \n\t"
         "movq (%1, %%"REG_a"), %%mm2    \n\t"
         "movq (%1, %3), %%mm1           \n\t"
diff -NaurbB --exclude=.svn ../ffmpeg/libavcodec/i386/dsputil_mmx_rnd.h ./libavcodec/i386/dsputil_mmx_rnd.h
--- ../ffmpeg/libavcodec/i386/dsputil_mmx_rnd.h	2006-06-30 10:41:13.000000000 +0700
+++ ./libavcodec/i386/dsputil_mmx_rnd.h	2006-06-30 09:50:02.000000000 +0700
@@ -28,7 +28,7 @@
     MOVQ_BFE(mm6);
     __asm __volatile(
         "lea    (%3, %3), %%"REG_a"     \n\t"
-        ".balign 8                      \n\t"
+        BALIGN_8
         "1:                             \n\t"
         "movq   (%1), %%mm0             \n\t"
         "movq   1(%1), %%mm1            \n\t"
@@ -69,7 +69,7 @@
         "movq   %%mm4, (%3)             \n\t"
         "add    %5, %3                  \n\t"
         "decl   %0                      \n\t"
-        ".balign 8                      \n\t"
+        BALIGN_8
         "1:                             \n\t"
         "movq   (%1), %%mm0             \n\t"
         "movq   (%2), %%mm1             \n\t"
@@ -110,7 +110,7 @@
     MOVQ_BFE(mm6);
     __asm __volatile(
         "lea        (%3, %3), %%"REG_a" \n\t"
-        ".balign 8                      \n\t"
+        BALIGN_8
         "1:                             \n\t"
         "movq   (%1), %%mm0             \n\t"
         "movq   1(%1), %%mm1            \n\t"
@@ -168,7 +168,7 @@
         "movq   %%mm5, 8(%3)            \n\t"
         "add    %5, %3                  \n\t"
         "decl   %0                      \n\t"
-        ".balign 8                      \n\t"
+        BALIGN_8
         "1:                             \n\t"
         "movq   (%1), %%mm0             \n\t"
         "movq   (%2), %%mm1             \n\t"
@@ -206,7 +206,7 @@
     __asm __volatile(
         "lea (%3, %3), %%"REG_a"        \n\t"
         "movq (%1), %%mm0               \n\t"
-        ".balign 8                      \n\t"
+        BALIGN_8
         "1:                             \n\t"
         "movq   (%1, %3), %%mm1         \n\t"
         "movq   (%1, %%"REG_a"),%%mm2   \n\t"
@@ -246,7 +246,7 @@
         "paddusw %%mm1, %%mm5           \n\t"
         "xor    %%"REG_a", %%"REG_a"    \n\t"
         "add    %3, %1                  \n\t"
-        ".balign 8                      \n\t"
+        BALIGN_8
         "1:                             \n\t"
         "movq   (%1, %%"REG_a"), %%mm0  \n\t"
         "movq   1(%1, %%"REG_a"), %%mm2 \n\t"
@@ -458,7 +458,7 @@
     __asm __volatile(
         "lea    (%3, %3), %%"REG_a"     \n\t"
         "movq   (%1), %%mm0             \n\t"
-        ".balign 8                      \n\t"
+        BALIGN_8
         "1:                             \n\t"
         "movq   (%1, %3), %%mm1         \n\t"
         "movq   (%1, %%"REG_a"), %%mm2  \n\t"
@@ -509,7 +509,7 @@
         "paddusw %%mm1, %%mm5           \n\t"
         "xor    %%"REG_a", %%"REG_a"    \n\t"
         "add    %3, %1                  \n\t"
-        ".balign 8                      \n\t"
+        BALIGN_8
         "1:                             \n\t"
         "movq   (%1, %%"REG_a"), %%mm0  \n\t"
         "movq   1(%1, %%"REG_a"), %%mm2 \n\t"
diff -NaurbB --exclude=.svn ../ffmpeg/libavcodec/i386/fdct_mmx.c ./libavcodec/i386/fdct_mmx.c
--- ../ffmpeg/libavcodec/i386/fdct_mmx.c	2006-06-30 10:41:13.000000000 +0700
+++ ./libavcodec/i386/fdct_mmx.c	2006-06-30 09:35:07.000000000 +0700
@@ -350,6 +350,67 @@
 
 static always_inline void fdct_row_sse2(const int16_t *in, int16_t *out)
 {
+#if defined(__APPLE__)
+    // Apple 'as' has a different macro syntax than FSF GCC 'as'
+    asm volatile(
+        ".macro FDCT_ROW_SSE2_H1        \n\t"
+        "movq      $0(%0), %%xmm2       \n\t"
+        "movq      $0+8(%0), %%xmm0     \n\t"
+        "movdqa    $1+32(%1), %%xmm3    \n\t"
+        "movdqa    $1+48(%1), %%xmm7    \n\t"
+        "movdqa    $1(%1), %%xmm4       \n\t"
+        "movdqa    $1+16(%1), %%xmm5    \n\t"
+        ".endmacro                      \n\t"
+        ".macro FDCT_ROW_SSE2_H2        \n\t"
+        "movq      $0(%0), %%xmm2       \n\t"
+        "movq      $0+8(%0), %%xmm0     \n\t"
+        "movdqa    $1+32(%1), %%xmm3    \n\t"
+        "movdqa    $1+48(%1), %%xmm7    \n\t"
+        ".endmacro                      \n\t"
+        ".macro FDCT_ROW_SSE2           \n\t"
+        "movq      %%xmm2, %%xmm1       \n\t"
+        "pshuflw   $$0x27, %%xmm0, %%xmm0  \n\t"
+        "paddsw    %%xmm0, %%xmm1       \n\t"
+        "psubsw    %%xmm0, %%xmm2       \n\t"
+        "punpckldq %%xmm2, %%xmm1       \n\t"
+        "pshufd    $$0x78, %%xmm1, %%xmm2  \n\t"
+        "pmaddwd   %%xmm2, %%xmm3       \n\t"
+        "pmaddwd   %%xmm1, %%xmm7       \n\t"
+        "pmaddwd   %%xmm5, %%xmm2       \n\t"
+        "pmaddwd   %%xmm4, %%xmm1       \n\t"
+        "paddd     %%xmm7, %%xmm3       \n\t"
+        "paddd     %%xmm2, %%xmm1       \n\t"
+        "paddd     %%xmm6, %%xmm3       \n\t"
+        "paddd     %%xmm6, %%xmm1       \n\t"
+        "psrad     $%3, %%xmm3          \n\t"
+        "psrad     $%3, %%xmm1          \n\t"
+        "packssdw  %%xmm3, %%xmm1       \n\t"
+        "movdqa    %%xmm1, $0(%4)       \n\t"
+        ".endmacro                      \n\t"
+        "movdqa    (%2), %%xmm6         \n\t"
+        "FDCT_ROW_SSE2_H1 0,0           \n\t"
+        "FDCT_ROW_SSE2 0                \n\t"
+        "FDCT_ROW_SSE2_H2 64,0          \n\t"
+        "FDCT_ROW_SSE2 64               \n\t"
+
+        "FDCT_ROW_SSE2_H1 16,64         \n\t"
+        "FDCT_ROW_SSE2 16               \n\t"
+        "FDCT_ROW_SSE2_H2 112,64        \n\t"
+        "FDCT_ROW_SSE2 112              \n\t"
+
+        "FDCT_ROW_SSE2_H1 32,128        \n\t"
+        "FDCT_ROW_SSE2 32               \n\t"
+        "FDCT_ROW_SSE2_H2 96,128        \n\t"
+        "FDCT_ROW_SSE2 96               \n\t"
+
+        "FDCT_ROW_SSE2_H1 48,192        \n\t"
+        "FDCT_ROW_SSE2 48               \n\t"
+        "FDCT_ROW_SSE2_H2 80,192        \n\t"
+        "FDCT_ROW_SSE2 80               \n\t"
+        :
+        : "r" (in), "r" (tab_frw_01234567_sse2.tab_frw_01234567_sse2), "r" (fdct_r_row_sse2.fdct_r_row_sse2), "i" (SHIFT_FRW_ROW), "r" (out)
+    );
+#else
     asm volatile(
         ".macro FDCT_ROW_SSE2_H1 i t    \n\t"
         "movq      \\i(%0), %%xmm2      \n\t"
@@ -408,6 +469,7 @@
         :
         : "r" (in), "r" (tab_frw_01234567_sse2.tab_frw_01234567_sse2), "r" (fdct_r_row_sse2.fdct_r_row_sse2), "i" (SHIFT_FRW_ROW), "r" (out)
     );
+#endif
 }
 
 static always_inline void fdct_row_mmx2(const int16_t *in, int16_t *out, const int16_t *table)
diff -NaurbB --exclude=.svn ../ffmpeg/libavcodec/i386/idct_mmx_xvid.c ./libavcodec/i386/idct_mmx_xvid.c
--- ../ffmpeg/libavcodec/i386/idct_mmx_xvid.c	2006-06-30 10:41:13.000000000 +0700
+++ ./libavcodec/i386/idct_mmx_xvid.c	2006-06-30 09:35:07.000000000 +0700
@@ -295,17 +295,17 @@
   "movq 8+" #A1 ",%%mm1                \n\t"/* 1     ; x7 x6 x5 x4*/\
   "movq %%mm0,%%mm2                \n\t"/* 2     ; x3 x2 x1 x0*/\
   "movq " #A3 ",%%mm3                  \n\t"/* 3     ; w05 w04 w01 w00*/\
-  "pshufw $0b10001000,%%mm0,%%mm0  \n\t"/* x2 x0 x2 x0*/\
+  "pshufw $0x88,%%mm0,%%mm0  \n\t"/* x2 x0 x2 x0*/\
   "movq 8+" #A3 ",%%mm4                \n\t"/* 4     ; w07 w06 w03 w02*/\
   "movq %%mm1,%%mm5                \n\t"/* 5     ; x7 x6 x5 x4*/\
   "pmaddwd %%mm0,%%mm3             \n\t"/* x2*w05+x0*w04 x2*w01+x0*w00*/\
   "movq 32+" #A3 ",%%mm6               \n\t"/* 6     ; w21 w20 w17 w16*/\
-  "pshufw $0b10001000,%%mm1,%%mm1  \n\t"/* x6 x4 x6 x4*/\
+  "pshufw $0x88,%%mm1,%%mm1  \n\t"/* x6 x4 x6 x4*/\
   "pmaddwd %%mm1,%%mm4             \n\t"/* x6*w07+x4*w06 x6*w03+x4*w02*/\
   "movq 40+" #A3 ",%%mm7               \n\t"/* 7    ; w23 w22 w19 w18*/\
-  "pshufw $0b11011101,%%mm2,%%mm2  \n\t"/* x3 x1 x3 x1*/\
+  "pshufw $0xDD,%%mm2,%%mm2  \n\t"/* x3 x1 x3 x1*/\
   "pmaddwd %%mm2,%%mm6             \n\t"/* x3*w21+x1*w20 x3*w17+x1*w16*/\
-  "pshufw $0b11011101,%%mm5,%%mm5  \n\t"/* x7 x5 x7 x5*/\
+  "pshufw $0xDD,%%mm5,%%mm5  \n\t"/* x7 x5 x7 x5*/\
   "pmaddwd %%mm5,%%mm7             \n\t"/* x7*w23+x5*w22 x7*w19+x5*w18*/\
   "paddd " #A4 ",%%mm3                 \n\t"/* +%4*/\
   "pmaddwd 16+" #A3 ",%%mm0            \n\t"/* x2*w13+x0*w12 x2*w09+x0*w08*/\
@@ -330,7 +330,7 @@
   "packssdw %%mm0,%%mm3            \n\t"/* 0     ; y3 y2 y1 y0*/\
   "packssdw %%mm4,%%mm7            \n\t"/* 4     ; y6 y7 y4 y5*/\
   "movq %%mm3, " #A2 "                  \n\t"/* 3     ; save y3 y2 y1 y0*/\
-  "pshufw $0b10110001,%%mm7,%%mm7  \n\t"/* y7 y6 y5 y4*/\
+  "pshufw $0xB1,%%mm7,%%mm7  \n\t"/* y7 y6 y5 y4*/\
   "movq %%mm7,8                +" #A2 "\n\t"/* 7     ; save y7 y6 y5 y4*/\
 
 
diff -NaurbB --exclude=.svn ../ffmpeg/libavcodec/i386/mmx.h ./libavcodec/i386/mmx.h
--- ../ffmpeg/libavcodec/i386/mmx.h	2006-06-30 10:41:13.000000000 +0700
+++ ./libavcodec/i386/mmx.h	2006-06-30 09:48:38.000000000 +0700
@@ -23,6 +23,14 @@
 #  define PTR_SIZE "4"
 #endif
 
+#if defined(__APPLE__)
+#  define BALIGN_8  ".align 3 \n\t"
+#  define BALIGN_16 ".align 4 \n\t"
+#else
+#  define BALIGN_8  ".balign 8 \n\t"
+#  define BALIGN_16 ".balign 16 \n\t"
+#endif
+
 /*
  * The type of an value that fits in an MMX register (note that long
  * long constant values MUST be suffixed by LL and unsigned long long
diff -NaurbB --exclude=.svn ../ffmpeg/libavcodec/i386/motion_est_mmx.c ./libavcodec/i386/motion_est_mmx.c
--- ../ffmpeg/libavcodec/i386/motion_est_mmx.c	2006-06-30 10:41:13.000000000 +0700
+++ ./libavcodec/i386/motion_est_mmx.c	2006-06-30 09:53:53.000000000 +0700
@@ -34,7 +34,7 @@
 {
     long len= -(stride*h);
     asm volatile(
-        ".balign 16                     \n\t"
+        BALIGN_16
         "1:                             \n\t"
         "movq (%1, %%"REG_a"), %%mm0    \n\t"
         "movq (%2, %%"REG_a"), %%mm2    \n\t"
@@ -70,7 +70,7 @@
 {
     long len= -(stride*h);
     asm volatile(
-        ".balign 16                     \n\t"
+        BALIGN_16
         "1:                             \n\t"
         "movq (%1, %%"REG_a"), %%mm0    \n\t"
         "movq (%2, %%"REG_a"), %%mm2    \n\t"
@@ -92,7 +92,7 @@
 {
     long len= -(stride*h);
     asm volatile(
-        ".balign 16                     \n\t"
+        BALIGN_16
         "1:                             \n\t"
         "movq (%1, %%"REG_a"), %%mm0    \n\t"
         "movq (%2, %%"REG_a"), %%mm2    \n\t"
@@ -118,7 +118,7 @@
 { //FIXME reuse src
     long len= -(stride*h);
     asm volatile(
-        ".balign 16                     \n\t"
+        BALIGN_16
         "movq "MANGLE(bone)", %%mm5     \n\t"
         "1:                             \n\t"
         "movq (%1, %%"REG_a"), %%mm0    \n\t"
@@ -155,7 +155,7 @@
 {
     long len= -(stride*h);
     asm volatile(
-        ".balign 16                     \n\t"
+        BALIGN_16
         "1:                             \n\t"
         "movq (%1, %%"REG_a"), %%mm0    \n\t"
         "movq (%2, %%"REG_a"), %%mm1    \n\t"
@@ -193,7 +193,7 @@
 {
     long len= -(stride*h);
     asm volatile(
-        ".balign 16                     \n\t"
+        BALIGN_16
         "1:                             \n\t"
         "movq (%1, %%"REG_a"), %%mm0    \n\t"
         "movq (%2, %%"REG_a"), %%mm1    \n\t"
diff -NaurbB --exclude=.svn ../ffmpeg/libavcodec/i386/mpegvideo_mmx.c ./libavcodec/i386/mpegvideo_mmx.c
--- ../ffmpeg/libavcodec/i386/mpegvideo_mmx.c	2006-06-30 10:41:13.000000000 +0700
+++ ./libavcodec/i386/mpegvideo_mmx.c	2006-06-30 09:51:26.000000000 +0700
@@ -66,7 +66,7 @@
                 "packssdw %%mm5, %%mm5          \n\t"
                 "psubw %%mm5, %%mm7             \n\t"
                 "pxor %%mm4, %%mm4              \n\t"
-                ".balign 16                     \n\t"
+                BALIGN_16
                 "1:                             \n\t"
                 "movq (%0, %3), %%mm0           \n\t"
                 "movq 8(%0, %3), %%mm1          \n\t"
@@ -129,7 +129,7 @@
                 "packssdw %%mm5, %%mm5          \n\t"
                 "psubw %%mm5, %%mm7             \n\t"
                 "pxor %%mm4, %%mm4              \n\t"
-                ".balign 16                     \n\t"
+                BALIGN_16
                 "1:                             \n\t"
                 "movq (%0, %3), %%mm0           \n\t"
                 "movq 8(%0, %3), %%mm1          \n\t"
@@ -222,7 +222,7 @@
                 "packssdw %%mm6, %%mm6          \n\t"
                 "packssdw %%mm6, %%mm6          \n\t"
                 "mov %3, %%"REG_a"              \n\t"
-                ".balign 16                     \n\t"
+                BALIGN_16
                 "1:                             \n\t"
                 "movq (%0, %%"REG_a"), %%mm0    \n\t"
                 "movq 8(%0, %%"REG_a"), %%mm1   \n\t"
@@ -285,7 +285,7 @@
                 "packssdw %%mm6, %%mm6          \n\t"
                 "packssdw %%mm6, %%mm6          \n\t"
                 "mov %3, %%"REG_a"              \n\t"
-                ".balign 16                     \n\t"
+                BALIGN_16
                 "1:                             \n\t"
                 "movq (%0, %%"REG_a"), %%mm0    \n\t"
                 "movq 8(%0, %%"REG_a"), %%mm1   \n\t"
@@ -357,7 +357,7 @@
                 "packssdw %%mm6, %%mm6          \n\t"
                 "packssdw %%mm6, %%mm6          \n\t"
                 "mov %3, %%"REG_a"              \n\t"
-                ".balign 16                     \n\t"
+                BALIGN_16
                 "1:                             \n\t"
                 "movq (%0, %%"REG_a"), %%mm0    \n\t"
                 "movq 8(%0, %%"REG_a"), %%mm1   \n\t"
@@ -418,7 +418,7 @@
                 "packssdw %%mm6, %%mm6          \n\t"
                 "packssdw %%mm6, %%mm6          \n\t"
                 "mov %3, %%"REG_a"              \n\t"
-                ".balign 16                     \n\t"
+                BALIGN_16
                 "1:                             \n\t"
                 "movq (%0, %%"REG_a"), %%mm0    \n\t"
                 "movq 8(%0, %%"REG_a"), %%mm1   \n\t"
diff -NaurbB --exclude=.svn ../ffmpeg/libavcodec/i386/mpegvideo_mmx_template.c ./libavcodec/i386/mpegvideo_mmx_template.c
--- ../ffmpeg/libavcodec/i386/mpegvideo_mmx_template.c	2006-06-30 10:41:13.000000000 +0700
+++ ./libavcodec/i386/mpegvideo_mmx_template.c	2006-06-30 09:52:00.000000000 +0700
@@ -111,7 +111,7 @@
             "pxor %%mm6, %%mm6                  \n\t"
             "psubw (%3), %%mm6                  \n\t" // -bias[0]
             "mov $-128, %%"REG_a"               \n\t"
-            ".balign 16                         \n\t"
+            BALIGN_16
             "1:                                 \n\t"
             "pxor %%mm1, %%mm1                  \n\t" // 0
             "movq (%1, %%"REG_a"), %%mm0        \n\t" // block[i]
@@ -155,7 +155,7 @@
             "pxor %%mm7, %%mm7                  \n\t" // 0
             "pxor %%mm4, %%mm4                  \n\t" // 0
             "mov $-128, %%"REG_a"               \n\t"
-            ".balign 16                         \n\t"
+            BALIGN_16
             "1:                                 \n\t"
             "pxor %%mm1, %%mm1                  \n\t" // 0
             "movq (%1, %%"REG_a"), %%mm0        \n\t" // block[i]
diff -NaurbB --exclude=.svn ../ffmpeg/libavcodec/i386/simple_idct_mmx.c ./libavcodec/i386/simple_idct_mmx.c
--- ../ffmpeg/libavcodec/i386/simple_idct_mmx.c	2006-06-30 10:41:13.000000000 +0700
+++ ./libavcodec/i386/simple_idct_mmx.c	2006-06-30 10:05:27.000000000 +0700
@@ -459,10 +459,10 @@
 
 
 //IDCT(      src0,   src4,   src1,    src5,    dst, rounder, shift)
-COL_IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),/nop, 20)
-COL_IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),/nop, 20)
-COL_IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),/nop, 20)
-COL_IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),/nop, 20)
+COL_IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),#nop, 20)
+COL_IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),#nop, 20)
+COL_IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),#nop, 20)
+COL_IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),#nop, 20)
 
 #else
 
@@ -783,10 +783,10 @@
 
 
 //IDCT(  src0,   src4,   src1,    src5,    dst, rounder, shift)
-IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),/nop, 20)
-IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),/nop, 20)
-IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),/nop, 20)
-IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),/nop, 20)
+IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),#nop, 20)
+IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),#nop, 20)
+IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),#nop, 20)
+IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),#nop, 20)
         "jmp 9f                         \n\t"
 
         "#.balign 16                    \n\t"\
@@ -860,10 +860,10 @@
         "movd %%mm5, 80+" #dst "        \n\t"
 
 //IDCT(  src0,   src4,   src1,    src5,    dst, rounder, shift)
-IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),/nop, 20)
-IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),/nop, 20)
-IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),/nop, 20)
-IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),/nop, 20)
+IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),#nop, 20)
+IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),#nop, 20)
+IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),#nop, 20)
+IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),#nop, 20)
         "jmp 9f                         \n\t"
 
         "#.balign 16                    \n\t"\
@@ -928,10 +928,10 @@
 
 
 //IDCT(  src0,   src4,   src1,    src5,    dst, rounder, shift)
-IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),/nop, 20)
-IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),/nop, 20)
-IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),/nop, 20)
-IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),/nop, 20)
+IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),#nop, 20)
+IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),#nop, 20)
+IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),#nop, 20)
+IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),#nop, 20)
         "jmp 9f                         \n\t"
 
         "#.balign 16                    \n\t"\
@@ -1007,10 +1007,10 @@
         "movd %%mm5, 80+" #dst "        \n\t"
 
 //IDCT(  src0,   src4,   src1,    src5,    dst, rounder, shift)
-IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),/nop, 20)
-IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),/nop, 20)
-IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),/nop, 20)
-IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),/nop, 20)
+IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),#nop, 20)
+IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),#nop, 20)
+IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),#nop, 20)
+IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),#nop, 20)
         "jmp 9f                         \n\t"
 
         "#.balign 16                    \n\t"\
@@ -1073,10 +1073,10 @@
 
 
 //IDCT(  src0,   src4,   src1,    src5,    dst, rounder, shift)
-IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),/nop, 20)
-IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),/nop, 20)
-IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),/nop, 20)
-IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),/nop, 20)
+IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),#nop, 20)
+IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),#nop, 20)
+IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),#nop, 20)
+IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),#nop, 20)
         "jmp 9f                         \n\t"
 
         "#.balign 16                    \n\t"\
@@ -1141,10 +1141,10 @@
 
 
 //IDCT(  src0,   src4,   src1,    src5,    dst, rounder, shift)
-IDCT(    0(%1), 64(%1), 32(%1),  96(%1),  0(%0),/nop, 20)
-//IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),/nop, 20)
-IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),/nop, 20)
-//IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),/nop, 20)
+IDCT(    0(%1), 64(%1), 32(%1),  96(%1),  0(%0),#nop, 20)
+//IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),#nop, 20)
+IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),#nop, 20)
+//IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),#nop, 20)
         "jmp 9f                         \n\t"
 
 
@@ -1217,10 +1217,10 @@
 
 
 //IDCT(  src0,   src4,   src1,    src5,    dst, rounder, shift)
-IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),/nop, 20)
-IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),/nop, 20)
-IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),/nop, 20)
-IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),/nop, 20)
+IDCT(    (%1), 64(%1), 32(%1),  96(%1),  0(%0),#nop, 20)
+IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),#nop, 20)
+IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),#nop, 20)
+IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),#nop, 20)
         "jmp 9f                         \n\t"
 
 
@@ -1259,10 +1259,10 @@
         "movq %%mm0, 80+" #dst "        \n\t"
 
 //IDCT(  src0,   src4,   src1,    src5,    dst, rounder, shift)
-IDCT(   0(%1), 64(%1), 32(%1),  96(%1),  0(%0),/nop, 20)
-//IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),/nop, 20)
-IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),/nop, 20)
-//IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),/nop, 20)
+IDCT(   0(%1), 64(%1), 32(%1),  96(%1),  0(%0),#nop, 20)
+//IDCT(   8(%1), 72(%1), 40(%1), 104(%1),  4(%0),#nop, 20)
+IDCT(  16(%1), 80(%1), 48(%1), 112(%1),  8(%0),#nop, 20)
+//IDCT(  24(%1), 88(%1), 56(%1), 120(%1), 12(%0),#nop, 20)
 
 
 #endif
